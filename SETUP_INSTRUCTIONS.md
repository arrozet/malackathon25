# ğŸš€ Brain AI Service - Instrucciones de Setup

## âš ï¸ IMPORTANTE: xAI vs Groq

**AclaraciÃ³n sobre las tecnologÃ­as:**

- **xAI** = Empresa de Elon Musk que desarrolla el modelo **Grok**
- **Grok-4 Fast Reasoning** = Modelo de IA que usamos (de xAI)
- **Groq** (con 'q') = Proveedor diferente de inferencia (NO es lo que usamos)

## ğŸ“‹ ConfiguraciÃ³n RÃ¡pida

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

Esto instalarÃ¡:
- `langchain-openai` (para conectar con xAI)
- `langchain` y `langchain-core`
- `tavily-python` (bÃºsqueda internet - opcional)
- `pandas`, `numpy`, `matplotlib` (anÃ¡lisis de datos)

### 2. Obtener API Key de xAI

1. Ve a **https://console.x.ai/**
2. Crea una cuenta o inicia sesiÃ³n
3. Navega a la secciÃ³n **API Keys**
4. Crea una nueva API key
5. Copia la key (empieza con `xai-...`)

### 3. Configurar variables de entorno

Edita `app/back/.env` y aÃ±ade:

```bash
# REQUERIDO - API Key de xAI para Grok-4 Fast Reasoning
XAI_API_KEY=xai_tu_key_aqui

# OPCIONAL - Solo si quieres usar bÃºsqueda en internet
TAVILY_API_KEY=tvly_tu_key_aqui
```

### 4. Verificar configuraciÃ³n

Revisa que el archivo `.env` tenga:

```bash
# Oracle Database (ya configurado)
ORACLE_USER=tu_usuario
ORACLE_PASSWORD=tu_password
ORACLE_DSN=tu_dsn
TNS_ADMIN=./app/oracle_wallet

# xAI para Grok-4 Fast Reasoning (NUEVO - AÃ‘ADIR)
XAI_API_KEY=xai_tu_key_aqui

# Tavily para bÃºsqueda en internet (OPCIONAL)
TAVILY_API_KEY=tvly_tu_key_aqui
```

## ğŸ§ª Probar el servicio

### OpciÃ³n 1: Test directo (Python)

```bash
# Probar todas las herramientas
python scripts/test_ai_service.py --mode all

# Solo probar herramientas individuales
python scripts/test_ai_service.py --mode tools

# Solo probar el servicio de IA
python scripts/test_ai_service.py --mode service

# Modo chat interactivo
python scripts/test_ai_service.py --mode interactive
```

### OpciÃ³n 2: Test via API REST

**Terminal 1** - Iniciar servidor:
```bash
cd app/back
python main.py
```

**Terminal 2** - Probar endpoints:
```bash
python scripts/test_ai_endpoints.py --test all
```

### OpciÃ³n 3: Test manual con cURL

```bash
# Health check
curl http://localhost:8000/ai/health

# Chat
curl -X POST http://localhost:8000/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿CuÃ¡ntos episodios hay en total?"}'

# AnÃ¡lisis
curl -X POST http://localhost:8000/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{"query": "Analiza la distribuciÃ³n por severidad"}'

# Diagrama
curl -X POST http://localhost:8000/ai/visualize \
  -H "Content-Type: application/json" \
  -d '{"description": "esquema de base de datos"}'
```

## ğŸ¯ Modelo Utilizado

- **Proveedor**: xAI (https://x.ai/)
- **Modelo**: `grok-4-fast-reasoning`
- **CaracterÃ­sticas**:
  - Ventana de contexto: 2M tokens
  - Razonamiento paso a paso
  - Soporte para tool calling
  - Optimizado para velocidad y coste

## ğŸ› ï¸ Herramientas Disponibles

1. **Oracle RAG** - Consulta BD con lenguaje natural
2. **Internet Search** - BÃºsqueda mÃ©dica actualizada (Tavily)
3. **Python Executor** - AnÃ¡lisis estadÃ­stico con Python
4. **Mermaid Generator** - Diagramas de flujo/ER/etc.

## â— Troubleshooting

### Error: "XAI_API_KEY no configurada"
âœ… **SoluciÃ³n**: AÃ±ade `XAI_API_KEY=xai_...` en `app/back/.env`
ğŸ“ **Obtener key**: https://console.x.ai/

### Error: "Connection pool not initialized"
âœ… **SoluciÃ³n**: Verifica que Oracle estÃ© configurado correctamente

### Error: Import error de langchain_openai
âœ… **SoluciÃ³n**: Ejecuta `pip install -r requirements.txt`

### El modelo no responde
âœ… **SoluciÃ³n**: 
- Verifica que la API key sea vÃ¡lida
- Prueba con: `curl https://api.x.ai/v1/models -H "Authorization: Bearer $XAI_API_KEY"`

## ğŸ“Š Ejemplo de Uso

```python
from app.back.services.ai_service import get_ai_service

# Inicializar servicio
ai = get_ai_service()

# Chat simple
result = ai.chat("Â¿CuÃ¡ntos episodios hay en 2023?")
print(result['response'])

# Con historial
history = [
    {"role": "user", "content": "Â¿CuÃ¡ntos episodios hay?"},
    {"role": "assistant", "content": "Hay 150,000 episodios"}
]
result = ai.chat("Â¿Y cuÃ¡l es la distribuciÃ³n por sexo?", chat_history=history)
print(result['response'])
```

## ğŸ“ Estructura de Archivos

```
app/back/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai_service.py              # Servicio principal (Grok-4)
â”‚   â””â”€â”€ tools/                     # Herramientas
â”‚       â”œâ”€â”€ oracle_rag_tool.py     # RAG Oracle
â”‚       â”œâ”€â”€ internet_search_tool.py # BÃºsqueda Tavily
â”‚       â”œâ”€â”€ python_executor_tool.py # Python seguro
â”‚       â””â”€â”€ mermaid_tool.py        # Diagramas Mermaid
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ ai.py                      # Endpoints REST
â””â”€â”€ schemas.py                     # Modelos Pydantic

scripts/
â”œâ”€â”€ test_ai_service.py             # Tests Python directo
â””â”€â”€ test_ai_endpoints.py           # Tests HTTP
```

## ğŸ“ Detalles TÃ©cnicos

### IntegraciÃ³n con xAI

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    api_key=os.getenv("XAI_API_KEY"),
    base_url="https://api.x.ai/v1",  # xAI API endpoint
    model="grok-4-fast-reasoning",    # Grok-4 Fast Reasoning
    temperature=0.3,                   # Razonamiento enfocado
    max_tokens=8000,
)
```

### Arquitectura

Sigue el patrÃ³n **Microservices + Clean Architecture**:
- **Tools Layer**: Herramientas especializadas
- **Services Layer**: LÃ³gica de negocio (ai_service.py)
- **Routers Layer**: Adaptadores HTTP (ai.py)
- **API Gateway**: OrquestaciÃ³n (main.py)

---

**Desarrollado para Malackathon 2025**  
**Modelo: Grok-4 Fast Reasoning (xAI)**  
**Framework: LangChain**

